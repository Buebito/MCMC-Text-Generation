{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "#Paqueterías de filtrado\n",
    "from nltk.corpus import stopwords\n",
    "from unidecode import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrimos el texto del Quijote\n",
    "#En este caso no filtraremos nada para que quede lo más parecido a un texto original. Esto claramente traerá problemas\n",
    "#de optimización y no generará texto tan coherente, pero más adelante lo intentaremos filtrando signos, puntuaciones y \n",
    "#conviritendo todo el texto a minusculas.\n",
    "with open(\"El Quijote.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "    words = content.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que recibe un texto en forma de lista y te calcula la frecuencia con la que aparecen ciertas palabras\n",
    "# despues de una palabra específica\n",
    "def probabilidadesTransición(words):\n",
    "# P será nuestro diccionario que tendrá como llave todas las palabras disponibles en el texto\n",
    "# y como valor OTRO DICCIONARIO, cuyo llave volverán a ser todas las palabras disponibles en el texto\n",
    "# y como valor la probabilidad que despues de la primera palabra (primera llave) siga la segunda palabra\n",
    "# (segunda llave)\n",
    "    P = {}\n",
    "#Recorremos cada palabra en la lista y analizamos la primera palabra y su sucesora\n",
    "    for i in range(len(words)-1):\n",
    "#X: presente, Y: futuro\n",
    "        X = words[i]\n",
    "        Y = words[i+1]\n",
    "#Si x no está en el diccionario, la agregamos y agregamos como valor otro diccionario incluyendo como llave a Y y agregarle\n",
    "# 1 a la frecuencia en la que aparece Y despues de X\n",
    "        if P.get(X) is None:\n",
    "            P[X] = {}\n",
    "            P[X][Y] = 1\n",
    "#Si X ya está, ahora checamos si Y está como llave en el diccionario en el valor de X\n",
    "        else:\n",
    "            if P[X].get(Y) is None:\n",
    "#Si no está ponemos como valor 1 y si sí está le agregamos 1 a la frecuencia\n",
    "                P[X][Y] = 1\n",
    "            else:\n",
    "                P[X][Y] += 1\n",
    "#Teniendo ya el diccionario con las frecuencias, ahora toca sacar las probabilidades de que salga cada palabra\n",
    "#Recorremos cada llave del diccionario y sumamos todos los valores encontrados en el diccionario de esa llave\n",
    "    for i in P.keys():\n",
    "        s = float(sum(P[i].values()))\n",
    "#Ahora trecorremos cada llave del segundo diccionario (del valor de la primera llave) y ajustamos el valor de la frecuencia\n",
    "#dividiendola entre la suma anterior y asi obteniendo una probabilidad elemento del (0,1)\n",
    "        for k in P[i].keys():\n",
    "            P[i][k] = P[i][k]/s\n",
    "#Devolvemos la matriz de transición\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la \"Matriz\" de transición basado en el texto del Quijote\n",
    "modelo = probabilidadesTransición(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora para crear el texto, despues de una palabra dada haremos lo sgiuiente.\n",
    "#Primero muestrearemos una palabra de la distribución de probabilidad obtenida (la matriz o diccionario creado en la función anterior)\n",
    "#utilizando el método de Metropolis-Hastings.\n",
    "#Para ello, primero crearemos una función alpha que penalice las transiciones poco probables. En este caso utilizaremos el negativo del \n",
    "#logaritmo de la probabilidad de transición.\n",
    "def alpha(P, current_word, next_word):\n",
    "\n",
    "#Este filtro es importante en este caso que no filtramos el texto (En el caso de no filtrar el texto no es neceario el if), ya que sucedía\n",
    "#muchas veces que la función estaba tratando de acceder a una llave existe en el diccionario o palabra en la matriz de probabilidades. \n",
    "#Esto sucedía por palabras que incluían un come o algun signo de admiración o exclamación.\n",
    "\n",
    "#Para corregir este error, se agregó una verificación en la función para asegurarnos de que solo intente acceder a claves existentes \n",
    "#en el diccionario P. Si la clave no existe, se devuelve un valor muy alto para que esa transición sea poco probable.\n",
    "    if current_word not in P or next_word not in P[current_word]:\n",
    "        return float('inf')\n",
    "    return -math.log(P[current_word][next_word])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora creamos la función para crear texto dada una palabra inicial.\n",
    "#La función recibe una \"matriz\" de transiciones (diccionario), una palabra inicial o semilla, el largo de palabras que se desea para el texto\n",
    "#y el número de iteraciones que se desea para para explorar el espacio de estados en el Metropolis-Hasting.\n",
    "#Aumentar el número de iteraciones puede mejorar la calidad del texto generado, pero también aumentará el tiempo de ejecución del algoritmo.\n",
    "def generate_text_mh(P, seed_word, length, iteraciones):\n",
    "\n",
    "#Creamos una lista donde almacenaremos las palabras que contendrá el texto.\n",
    "#La variable current_word cambiará conforme vayamos agregando palabras al texto, empezando por la semilla\n",
    "    current_word = seed_word\n",
    "    text = [current_word]\n",
    "\n",
    "#Recorremos el largo que queremos que sea el texto\n",
    "    for i in range(length):\n",
    "\n",
    "#Vemos si la palabra se encuentra en el diccionario, es decir, si el autor utilizaría esa palabra en alguno de sus textos\n",
    "#Si no es el caso, tronamos la función\n",
    "        if P.get(current_word) is None:\n",
    "            print(\"Saavedra jamás diría eso\")\n",
    "            break\n",
    "\n",
    "#Si la palabra sí está en el diccionario (matriz), comenzamos el algoritmo Metropolis-Hasting para muestrear la siguiente palabra en la cadena\n",
    "#Esto lo haremos el numero de iteraciones que se desee\n",
    "        for i in range(iteraciones):\n",
    "\n",
    "#Dada la palabra en la que nos encontremos, sacaremos del diccionario las palabras que le pueden seguir como una lista, y la\n",
    "#probabilidad como otra\n",
    "#Recordemos que la matriz de transiciones es un diccionario de diccionarios, entonces al buscar la palabra actual current_word\n",
    "#en el diccionario, nos mostrará otro diccionario con las palabras que le pueden seguir como llaves y como valores las probabilidades\n",
    "            next_word_candidates = list(P[current_word].keys())\n",
    "            next_word_probabilities = list(P[current_word].values())\n",
    "\n",
    "#Teniendo la lista de palabras candidatas y probabilidades, seleccionamos una palabra utilizando la distribución propuesta \n",
    "#En este caso, proponemos distribución del modelo que sacamos anterirmente, es decir, utilizando la matriz de trancisiones (diccionario)\n",
    "#También podríamos proponer que la distribución fuera uniforme para todas las palabras, pero tendría un tiempo de convergencia menor.\n",
    "            proposed_next_word = random.choices(next_word_candidates, weights=next_word_probabilities, k=1)[0]\n",
    "\n",
    "#Calculamos la razón de aceptación con la función alpha\n",
    "# \"Lanzamos la moneda\" y vemos si nos quedamos con la palabra o nos movemos a otra\n",
    "\n",
    "# Probabilidad de no cambiar\n",
    "            a = alpha(P, current_word, text[-1])\n",
    "# Probabilidad de cambio a siguiente palabra\n",
    "            a2 = alpha(P, current_word, proposed_next_word)\n",
    "#Calculamos la propabilidad de aceptación\n",
    "            probabilidad_aceptacion = min(1, math.exp(a - a2))\n",
    "\n",
    "# Vemos si aceptamos o rechazamos la palabra propuesta, generando valores de la distribucion Unif(0,1) y viendo si es menor a \n",
    "# Mi probabilidad de aceptación\n",
    "            if random.random() < probabilidad_aceptacion:\n",
    "#Si es mayor, definimos la nueva palabra\n",
    "                next_word = proposed_next_word\n",
    "                break\n",
    "#Al terminar las iteraciones agregamos la nueva palabra a la lista\n",
    "        text.append(next_word)\n",
    "#Cambiamos la variable current_word a la nueva palabra agregada para seguir con el ciclo otra vez\n",
    "        current_word = next_word\n",
    "\n",
    "#Terminando el algoritmo, regresamos el texto todo junto\n",
    "    return ' '.join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perro por satisfacer del caso; que tanto que te puedo que ansí lo que la verdad, no me veas lo fuera, sino que no le dijo en este traje, rodearon a sí, y piensa que a tu suerte! Vete por estas invenciones y a lo que vuestra merced, señor -replicó Sancho--;\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso con una palabra inicial específica\n",
    "seed_word = \"perro\"\n",
    "generated_text = generate_text_mh(modelo, seed_word, length=50, iteraciones=10000)\n",
    "print(generated_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora limpiemos el texto a ver si tenemos convergencia más rápida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recibe una string y devuelve la string sin puntuaciones o signos raros.\n",
    "\n",
    "def limpieza(text):\n",
    "#Unidecode toma un objeto de cadena, que posiblemente contenga caracteres no ASCII, y devuelve una cadena que se puede \n",
    "#codificar de forma segura en ASCII. En este caso se utilizó para remover acentos y emojis\n",
    "    text = unidecode(text)\n",
    "#Minúsculas\n",
    "    text = text.lower()\n",
    "#Eliminar signos de interrogación, exclamación y otros\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "#----------------------\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"El Quijote.txt\", \"r\", encoding=\"utf-8\")\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=limpieza(text)\n",
    "words = text.split()\n",
    "modelo = probabilidadesTransición(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perro con estos mas dura pena de enconar como el quedo dormido mas de camila juntamente y esconderme de cosas tan suave canto y casi dos libros cuentan las circunvecinas no tiene cosa senor licenciado que lotario de aquella aldea dejando admirados los pastores se consolase no me place dijo vive\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso con una palabra inicial específica\n",
    "seed_word = \"perro\"\n",
    "generated_text = generate_text_mh(modelo, seed_word, length=50, iteraciones=10000)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
