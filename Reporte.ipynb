{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC para generación de texto coherente"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice:\n",
    "* [Introducción](#intro)\n",
    "* [Metodología](#meth)\n",
    "* [Implementación y resultados](#imp-res)\n",
    "    * [Limpieza de Texto](#limp)\n",
    "    * [Matriz de Transición](#pmatriz)\n",
    "    * [Implementación del algoritmo Metropolis-Hasting](#mh)\n",
    "* [Conclusiones](#conc)\n",
    "* [Bibliografía](#ref)\n",
    "* [Anexos](#anex)\n",
    "    * [Código adicional](#code)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción <a class=\"anchor\" id=\"intro\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Día con día, diversas aplicaciones nos ayudan a producir texto, ya sea Word ayudándonos a crear un documento sin errores gramaticales u ortográficos, Google dándonos resúmenes cortos y rápidos de páginas webs o hasta Siri que se comunica con nosotros de forma particularmente humana, pero ¿alguna vez te has preguntado cómo es que una computadora encargada de \"dar vida\" a estas aplicaciones, que únicamente sabe pensar en ceros y unos, puede interpretar y producir lenguaje humano? El Procesamiento del Lenguaje Natural (NLP) es un campo de estudio de la inteligencia artificial que se enfoca en la interacción entre las computadoras y el lenguaje humano. Éste utiliza algoritmos y técnicas para comprender, interpretar y generar texto (Jurafsky & Martin, 2020). Una de las herramientas más utilizadas en el NLP son las cadenas de Márkov, que son modelos matemáticos que representan la probabilidad de transición entre diferentes estados de un proceso estocástico.\n",
    "\n",
    "Si quisieramos ir aún más lejos, podríamos implementar herramientas un poco más poderosas como el MCMC. El Muestreo de Markov Chain Monte Carlo (MCMC) es una técnica de muestreo ampliamente utilizada en estadística y aprendizaje automático para estimar distribuciones de probabilidad y simular sistemas complejos (Robert & Casella, 2013). El objetivo de este proyecto es simular un texto que imite el estilo de escritura de un autor a elección del usuario. Pero esto puede ser volverse bastante complicado pues cada autor tiene su propia forma de escribir y expresarse, es decir, cada quién tiene sus vicios del lenguaje, tono, etc. De igual manera, no es lo mismo reproducir el texto plano de un libro que el un tweet, ya que cada uno tiene sus dificultades de procesamiento. Mientras el texto de un libro puede llegar a ser complejo por las herramientas literarias que puede llegar a utilizar, un tweet igual puede mostrar dificultades por los recursos que utilizan como las menciones, hashtags, emojis, etc.\n",
    "\n",
    "En este reporte, describimos la implementación de un algoritmo de MCMC llamado Metropolis-Hastings para generar texto coherente a partir de un texto dado (o palabra). La generación de texto coherente es un problema relativamente dificil en el procesamiento del lenguaje natural y el aprendizaje automático, y MCMC ofrece una forma sistemática y flexible de explorar diferentes combinaciones de palabras para generar texto significativo (Andrieu et al., 2003).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodología <a class=\"anchor\" id=\"meth\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método MCMC (Markov Chain Monte Carlo) es una técnica de simulación numérica que se utiliza para estimar la distribución de probabilidad de una variable aleatoria (Robert & Casella, 2013). La idea detrás del método es construir una cadena de Markov que tenga como distribución estacionaria la distribución de probabilidad que se quiere estimar.\n",
    "\n",
    "Supongamos que nosotros queremos crear un texto aleatorio parecido de un autor $X$. Cada palabra que se genere dentro del texto, seguirá una distribución teórica $\\pi$, la cual deseamos simular para generar el texto. ¿Cómo podríamos construir una cadena ergódica que admita a $\\pi$ como distribución invariante? \n",
    "\n",
    "Dado un texto, podemos crear una matriz de transición o estados $P$ que nos indique cuál es la probabilidad de pasar de una palabra dada a otra. Para ello proponemos el siguiente pseudocódigo:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenizamos el texto en una lista\n",
    "- Recorremos cada palabra de la lista\n",
    "- Para cada palabra realizamos lo siguiente:\n",
    "    - Guardamos la siguiente palabra (ya sea en un array o diccionario) junto con un 1 que servirá de contador\n",
    "    - Si ya se había guardado esa palabra antes, le sumamos 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagram0](RenderImages/Diagram0.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tener la matriz de transición y suponiendo que el texto es una cadena ergódica, entonces por teorema tenemos que, sean $i$ y $j$ palabras del texto:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\pi(j)=\\lim_{n \\to \\infty}p_{ij}^{(n)}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y por teorema ergódico, podemos estimar esperanzas de funciones utilizando promedios aritméticos y así simular la mejor opción para la siguiente palabra en el texto. \n",
    "\n",
    "Dado todo lo anterior, para generar un texto después de una palabra dada, primero podríamos proponer los candidatos que muestra la matriz $P$ y escoger alguno dada su distribución propuesta $\\pi_0$. \n",
    "Para que el texto  converja a lo que queremos, es decir que acepte a $\\pi$ como distribución invariante, calculamos un coeficiente o probabilidad de aceptación para ver si nos quedamos con la palabra propuesta o no, lo cual nos creará una nueva probabilidad de transición. Esto se simulará para un número grande de iteraciones, ya que por TCL, entre más iteraciones se tengan, más preciso y de mejor calidad será el texto que se genere, pero obviamente tomará más tiempo.\n",
    "\n",
    "Para ello, proponemos el siguiente pseudocódigo para la generación de texto:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagram2](RenderImages/Diagram2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación y resultados <a class=\"anchor\" id=\"imp-res\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de Texto <a class=\"anchor\" id=\"limp\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de implementar el algoritmo hay varias cosas que se deben tomar en cuenta. Primero, debemos pensar si queremos filtrar el texto antes de aplicar el algoritmo, ya que los signos de puntuación, caracteres especiales (no ASCII) y hasta las letras mayúsculas pueden alterar la forma en la que se genera el texto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagram1](RenderImages/Diagram1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al escoger no filtrar nuestro texto, corremos el riesgo que nuestro texto no sea tan aleatorio como quisiéramos y que no sea del todo lógico o coherente. Por el otro lado, filtrarlo haría que la convergencia sea más rápida, creando un texto más conciso en el estilo deseado, pero sin ningún sentido lógico gramatical; por ejemplo, en español los acentos pueden hace que todo el sentido de una palabra sea completamente distinto.\n",
    "\n",
    "Esta misma cuestión sobre el filtrado me trajo una duda distinta: ¿qué sucedería si quisiéramos generar tweets? El problema de querer filtrar texto en un tweet es que al eliminar caracteres especiales como hashtags y menciones corremos el riesgo de romper completamente con la lógica del tweet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hashtags](RenderImages/tweet.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por eso mismo se implementó el algoritmo no únicamente con textos en español, sino también en inglés, aplicando en ambos casos un caso donde se ha filtrado el texto y uno en el que no. En el caso de los tweets, decidimos no filtrar nada para ver qué sucedía. Los textos utilizados para la implementación fueron “Don Quijote de la Mancha” y “El retrato de Dorian Gray” ambos en formato de texto. Para los tweets se descargó una base de datos en formato csv de la página [TTA - Search](https://www.thetrumparchive.com/). Los códigos para la lectura de los archivos y la limpieza del texto se encuentran en el apartado de Código Adicional en Anexos y lo que hacen es leer los distintos archivos, ya sea limpiarlos o no, y crear una lista con las palabras los textos para que se puedan procesar luego."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Transición <a class=\"anchor\" id=\"pmatriz\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar MCMC en la generación de texto, primero construimos una matriz de transición que describe las probabilidades de transición entre palabras consecutivas en un texto. Para ello construimos una función que toma una lista de palabras y crea un diccionario anidado que representa la matriz de transición. Cada palabra en el texto se utiliza como una llave en el diccionario, y sus valores son otro diccionario que contiene las palabras que siguen a la palabra clave y la frecuencia relativa con la que aparecen. Esta matriz de transición se utiliza para guiar la generación de texto en el algoritmo de MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que recibe un texto en forma de lista y te calcula la frecuencia con la que aparecen ciertas palabras\n",
    "# despues de una palabra específica\n",
    "def probabilidadesTransición(words):\n",
    "# P será nuestro diccionario que tendrá como llave todas las palabras disponibles en el texto\n",
    "# y como valor OTRO DICCIONARIO, cuyo llave volverán a ser todas las palabras disponibles en el texto\n",
    "# y como valor la probabilidad que despues de la primera palabra (primera llave) siga la segunda palabra\n",
    "# (segunda llave)\n",
    "    P = {}\n",
    "#Recorremos cada palabra en la lista y analizamos la primera palabra y su sucesora\n",
    "    for i in range(len(words)-1):\n",
    "#X: presente, Y: futuro\n",
    "        X = words[i]\n",
    "        Y = words[i+1]\n",
    "#Si x no está en el diccionario, la agregamos y agregamos como valor otro diccionario incluyendo como llave a Y y agregarle\n",
    "# 1 a la frecuencia en la que aparece Y despues de X\n",
    "        if P.get(X) is None:\n",
    "            P[X] = {}\n",
    "            P[X][Y] = 1\n",
    "#Si X ya está, ahora checamos si Y está como llave en el diccionario en el valor de X\n",
    "        else:\n",
    "            if P[X].get(Y) is None:\n",
    "#Si no está ponemos como valor 1 y si sí está le agregamos 1 a la frecuencia\n",
    "                P[X][Y] = 1\n",
    "            else:\n",
    "                P[X][Y] += 1\n",
    "#Teniendo ya el diccionario con las frecuencias, ahora toca sacar las probabilidades de que salga cada palabra\n",
    "#Recorremos cada llave del diccionario y sumamos todos los valores encontrados en el diccionario de esa llave\n",
    "    for i in P.keys():\n",
    "        s = float(sum(P[i].values()))\n",
    "#Ahora trecorremos cada llave del segundo diccionario (del valor de la primera llave) y ajustamos el valor de la frecuencia\n",
    "#dividiendola entre la suma anterior y asi obteniendo una probabilidad elemento del (0,1)\n",
    "        for k in P[i].keys():\n",
    "            P[i][k] = P[i][k]/s\n",
    "#Devolvemos la matriz de transición\n",
    "    return P"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación del algoritmo Metropolis-Hasting <a class=\"anchor\" id=\"mh\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar el algoritmo, crearemos pimero una función alpha que calcule la propapilidad de aceptación de la nueva palabra y que penalice las transiciones poco probables, calculando el negativo del logaritmo de la probabilidad de transición, ya que son probabilidades, es decir $p\\in (0,1)$. Esta función, recibirá la palabra actual, la propuesta siguiente y la matriz de transición, devolviendo así una propabilidad de aceptación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(P, current_word, next_word):\n",
    "\n",
    "#Este filtro es importante en este caso que no filtramos el texto (En el caso de no filtrar el texto no es neceario el if), ya que sucedía\n",
    "#muchas veces que la función estaba tratando de acceder a una llave existe en el diccionario o palabra en la matriz de probabilidades. \n",
    "#Esto sucedía por palabras que incluían un come o algun signo de admiración o exclamación.\n",
    "\n",
    "#Para corregir este error, se agregó una verificación en la función para asegurarnos de que solo intente acceder a claves existentes \n",
    "#en el diccionario P. Si la clave no existe, se devuelve un valor muy alto para que esa transición sea poco probable.\n",
    "    if current_word not in P or next_word not in P[current_word]:\n",
    "        return float('inf')\n",
    "    return -math.log(P[current_word][next_word])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero muestrearemos una palabra de la distribución de probabilidad obtenida (la matriz o diccionario creado en la función anterior). Despues implementamos el algoritmo de Metropolis-Hastings para generar texto utilizando la matriz de transición $P$ y la propabilidad de aceptación $\\alpha$. La función toma como entrada una palabra inicial (seed_word), la longitud deseada del texto generado y el número de iteraciones para realizar en cada paso del algoritmo (entre más iteraciones, más preciso) y regresa una string variable que será nuestro texto.  Al utilizar la probabilidad de aceptación y la alpha asociada con las palabras, el algoritmo favorece las transiciones de palabras con mayor probabilidad, lo que puede resultar en un texto generado más coherente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_mh(P, seed_word, length, iteraciones):\n",
    "\n",
    "#Creamos una lista donde almacenaremos las palabras que contendrá el texto.\n",
    "#La variable current_word cambiará conforme vayamos agregando palabras al texto, empezando por la semilla\n",
    "    current_word = seed_word\n",
    "    text = [current_word]\n",
    "\n",
    "#Recorremos el largo que queremos que sea el texto\n",
    "    for i in range(length):\n",
    "\n",
    "#Vemos si la palabra se encuentra en el diccionario, es decir, si el autor utilizaría esa palabra en alguno de sus textos\n",
    "#Si no es el caso, tronamos la función\n",
    "        if P.get(current_word) is None:\n",
    "            print(\"Saavedra jamás diría eso\")\n",
    "            break\n",
    "\n",
    "#Si la palabra sí está en el diccionario (matriz), comenzamos el algoritmo Metropolis-Hasting para muestrear la siguiente palabra en la cadena\n",
    "#Esto lo haremos el numero de iteraciones que se desee\n",
    "        for i in range(iteraciones):\n",
    "\n",
    "#Dada la palabra en la que nos encontremos, sacaremos del diccionario las palabras que le pueden seguir como una lista, y la\n",
    "#probabilidad como otra\n",
    "#Recordemos que la matriz de transiciones es un diccionario de diccionarios, entonces al buscar la palabra actual current_word\n",
    "#en el diccionario, nos mostrará otro diccionario con las palabras que le pueden seguir como llaves y como valores las probabilidades\n",
    "            next_word_candidates = list(P[current_word].keys())\n",
    "            next_word_probabilities = list(P[current_word].values())\n",
    "\n",
    "#Teniendo la lista de palabras candidatas y probabilidades, seleccionamos una palabra utilizando la distribución propuesta \n",
    "#En este caso, proponemos distribución del modelo que sacamos anterirmente, es decir, utilizando la matriz de trancisiones (diccionario)\n",
    "#También podríamos proponer que la distribución fuera uniforme para todas las palabras, pero tendría un tiempo de convergencia menor.\n",
    "            proposed_next_word = random.choices(next_word_candidates, weights=next_word_probabilities, k=1)[0]\n",
    "\n",
    "#Calculamos la razón de aceptación con la función alpha\n",
    "# \"Lanzamos la moneda\" y vemos si nos quedamos con la palabra o nos movemos a otra\n",
    "\n",
    "# Probabilidad de no cambiar\n",
    "            a = alpha(P, current_word, text[-1])\n",
    "# Probabilidad de cambio a siguiente palabra\n",
    "            a2 = alpha(P, current_word, proposed_next_word)\n",
    "#Calculamos la propabilidad de aceptación\n",
    "            probabilidad_aceptacion = min(1, math.exp(a - a2))\n",
    "\n",
    "# Vemos si aceptamos o rechazamos la palabra propuesta, generando valores de la distribucion Unif(0,1) y viendo si es menor a \n",
    "# Mi probabilidad de aceptación\n",
    "            if random.random() < probabilidad_aceptacion:\n",
    "#Si es mayor, definimos la nueva palabra\n",
    "                next_word = proposed_next_word\n",
    "                break\n",
    "#Al terminar las iteraciones agregamos la nueva palabra a la lista\n",
    "        text.append(next_word)\n",
    "#Cambiamos la variable current_word a la nueva palabra agregada para seguir con el ciclo otra vez\n",
    "        current_word = next_word\n",
    "\n",
    "#Terminando el algoritmo, regresamos el texto todo junto\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Textos en Español"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Seed: \"amarillo\"; Tamaño: 50 </em><br><br>\n",
    "<strong>Sin Filtrar</strong>: amarillo y sólo os conozco, por hecho con mucho cuando, movido a todos se llamaba Juan Rufo, jurado nada), que estáis tan buena fe se podrían reprensentallas, y los rostros son los desengaños no se contentaron de caballería y temerosas y la historia de rescate o a quien tiene usurpado; que\n",
    "\n",
    "<strong>Texto Filtrado</strong>: amarillo y mas deseos y diciendo ah traidor que se le parecio y guy de aquella gran reina de llamar el primero de leer de caballerias que estaban la noticia del caballo rocinante albarde el de don quijote el cual ya pasados siglos y aunque la hacienda alli tendido en ningun"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Textos en Inglés"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Seed: \"yellow\"; Tamaño: 50 </em><br><br>\n",
    "<strong>Sin Filtrar</strong>: yellow piazza of evil, with myriads of myself,\" said Dorian. Tell me know their coats and give him the aged, I to put her with dyed hair and you really changed? Or rather, I am afraid of, I am quite obvious. But it was, but that I can it began to\n",
    "\n",
    "<strong>Texto Filtrado</strong>: yellow chinese box twentyseven i was nothing fearful about it all a burden to death of the women were pictured to see the emotion no you must come some strange conjectures as much better go through long _clarin_ of the room that it is like fire to linger sometimes think certainly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweet de Donald Trump"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Seed: \"America\"; Tamaño:40 </em><br><br>\n",
    "\n",
    "\"America could extort $1,000,000.00 from the crowd. He is willing to Create Jobs, Jobs, Border than a tax cuts &amp, @gatewaypundit. @jheil at R's. Shame! ....President. We need to establish a country could be winning their best opportunity to a great\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones <a class=\"anchor\" id=\"conc\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo Metropolis-Hastings es bastante bueno generar muestras de distribuciones de probabilidad no triviales desconocidas (como los textos en nuestro caso) mediante la construcción de una cadena de Markov cuya distribución estacionaria coincide con la distribución objetivo. Como pudimos ver, es relativamente fácil de implementar y converge relativamente rápido si se tiene una muestra grande de datos, regalando resultado no tan malos. De igualmanera se puede adaptar a una amplia variedad de problemas.\n",
    "\n",
    "Sin embargo, el algoritmo Metropolis-Hastings también tiene algunas desventajas. En primer lugar, puede ser ineficiente en ciertos casos, ya que la convergencia a la distribución estacionaria puede ser lenta. La elección de una distribución propuesta adecuada es crucial para la eficiencia del algoritmo, pero esto puede ser difícil en la práctica. \n",
    "\n",
    "Algunas formas en las que se mejoraría el MCMC para la generación de texto pueden ser las siguientes:\n",
    "1. Utilizar un modelo de lenguaje más avanzado, como un modelo de n-gramas o un modelo neuronal, para obtener mejores estimaciones de las probabilidades de transición entre palabras.\n",
    "\n",
    "2. Mejorar la generación de texto utilizando modelos más avanzados, como redes neuronales recurrentes (RNN)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias <a class=\"anchor\" id=\"ref\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Repositorio del proyecto\n",
    "* https://github.com/Buebito/MCMC-Text-Generation.git\n",
    "##### Bibliografía\n",
    "* Andrieu, C., de Freitas, N., Doucet, A. et al. An Introduction to MCMC for Machine Learning. Machine Learning 50, 5–43 (2003). https://doi.org/10.1023/A:1020281327116\n",
    "* Gerlach, M. and Font-Clos, F. (2020) “A standardized project gutenberg corpus for statistical analysis of Natural Language and Quantitative Linguistics,” Entropy, 22(1), p. 126. Available at: https://doi.org/10.3390/e22010126. \n",
    "* Jurafsky, D., & Martin, J. H. (2020). Speech and Language Processing. An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition (3rd edition).\n",
    "* Robert, C.; Casella, G. (2010). Introducing Monte Carlo Methods with R. Berlin: Springer-Verlag.\n",
    "* (2018). Text generation using Monte-Carlo Sampling.\n",
    "\n",
    "##### Archivos externos\n",
    "* Brendan (2016) “The Trump Archive.” Available at: https://www.thetrumparchive.com. \n",
    "* Jesús  Darío (2017) El quijote en Texto Plano, El Quijote. GitHub. Available at: https://gist.github.com/jsdario/6d6c69398cb0c73111e49f1218960f79 (Accessed: April 21, 2023). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anexos <a class=\"anchor\" id=\"anex\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Jupyter Notebook completo del proyecto con todo el código y los resultados obtenidos, así como este reporte, los archivos txt y la base de datos csv se pueden encontrar en el repositorio de github [MCMC-Text-Generation](https://github.com/Buebito/MCMC-Text-Generation.git), el cual se seguirá actualizando."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código adicional <a class=\"anchor\" id=\"code\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paqueterías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "#Paqueterías de filtrado\n",
    "from nltk.corpus import stopwords\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "from collections.abc import MutableMapping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lectura de texto y Tokenizado en lista de palabras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sin limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abre el archivo txt y lo convierte en una lista de palabras\n",
    "with open(\"El Quijote.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "    words = content.split()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Con limpieza de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recibe una string y devuelve la string sin puntuaciones o signos raros.\n",
    "\n",
    "def limpieza(text):\n",
    "#Unidecode toma un objeto de cadena, que posiblemente contenga caracteres no ASCII, y devuelve una cadena que se puede \n",
    "#codificar de forma segura en ASCII. En este caso se utilizó para remover acentos y emojis\n",
    "    text = unidecode(text)\n",
    "#Minúsculas\n",
    "    text = text.lower()\n",
    "#Eliminar signos de interrogación, exclamación y otros\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "#----------------------\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abre el texto y se guarda en string\n",
    "file = open(\"El Quijote.txt\", \"r\", encoding=\"utf-8\")\n",
    "text = file.read()\n",
    "file.close()\n",
    "#Lo limpia y lo tokeniza\n",
    "text=limpieza(text)\n",
    "words = text.split()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lectura de CVS (como dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets_01-08-2021.csv')\n",
    "\n",
    "#función que transforma una columna de un dataframe en un texto plano\n",
    "def colToText(df_columna):\n",
    "    l=list(df_columna)\n",
    "    return \" \".join(l)\n",
    "\n",
    "#lo convertimos en lista de palabras\n",
    "text=colToText(df.text)\n",
    "words=text.split()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ejemplo de cómo implementar las funciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo ya la lista de palabras, sea filtrada o no, creamos el modelo de la cadena de Márkov, es decir la matriz de transición, con la función <em>probabilidadesTransición()</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = probabilidadesTransición(words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo el modelo o la matriz P ya lista, creamos una variable <em>seed_word</em> que será la primera palabra con la que comenzará el texto. También sería prudente considerar crear una variable <em>length</em>, para el tamaño del texto deseado (tamaño en palabras) e <em>iteraciones</em>, para el numero de iteraciones que se deseen para el Metropolis-Hasting.\n",
    "\n",
    "Una vez teniendo las variables, las agregamos a la función <em>generate_text_mh<em> para que nos genere el texto deseado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_word = \"amarillo\"\n",
    "generated_text = generate_text_mh(modelo, seed_word, length=50, iteraciones=100000)\n",
    "print(generated_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código de Diagramas de Pseudocódigo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR;\n",
    "    A[\"current_word\"]-->B[\"next_word\"]-->C[\"Is P[current_word][next_word] in P?\"]\n",
    "    C-->|YES|D[\"Add P[current_word][next_word] + 1\"]\n",
    "    C-->|NO|E[\"Set P[current_word][next_word] = 1\"]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart TD;\n",
    "    A(\"current_word\")-->B(\"Propuesta de Palabra\")-->C(\"Calculamos alpha\")-->D(\"Calculamos Probabilidad de Aceptación Y\");\n",
    "    D-->E[\"Simulamos X-Unif(0,1)\"]-->F[\"Aceptamos si X < Y\"]-->B\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart LR;\n",
    "    A(\"ese fue el fin.\")-->B[\"CAPITULO 2\"];\n",
    "    C(\"ese fue el fin\")-->D[\"de la historia de nuestro querido amigo\"];\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
